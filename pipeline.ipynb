{
 "metadata": {
  "name": "",
  "signature": "sha256:9f6323f6bde28e719841c9f4e9cc5fb660f391d09c68ab7744040b2a687b87d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from graphlab import *\n",
      "import numpy as np\n",
      "\n",
      "import graphlab as gl\n",
      "\n",
      "train_data = gl.SFrame.read_csv('./train.csv', error_bad_lines=False, column_type_hints = {'id': int, 'latitude': float, \n",
      "                            'longitude': float,\n",
      "                            'num_votes': int,\n",
      "                            'num_comments': int,\n",
      "                            'num_views': int})\n",
      "\n",
      "test_data = gl.SFrame.read_csv('./test.csv', error_bad_lines=False, column_type_hints = {'id': int, 'latitude': float, \n",
      "                            'longitude': float,\n",
      "                            'num_votes': int,\n",
      "                            'num_comments': int,\n",
      "                            'num_views': int})\n",
      "\n",
      "train_data['summary_length'] = train_data['summary'].apply(lambda x: len(x.strip().split()))\n",
      "test_data['summary_length'] = test_data['summary'].apply(lambda x: len(x.strip().split()))\n",
      "\n",
      "train_data['description_words'] = train_data['description'].count_words()\n",
      "test_data['description_words'] = test_data['description'].count_words()\n",
      "\n",
      "train_data['summary_words'] = train_data['summary'].count_words()\n",
      "test_data['summary_words'] = test_data['summary'].count_words()\n",
      "\n",
      "train_data.head(1)\n",
      "test_data.head(1)\n",
      "\n",
      "from collections import defaultdict\n",
      "word_dict = defaultdict(int)\n",
      "for row in train_data['summary_words']:\n",
      "    for w, c in row.iteritems():\n",
      "        word_dict[w] += c\n",
      "\n",
      "stop_words = 'common-english-words.txt'\n",
      "stop_words_list = []\n",
      "\n",
      "for line in file('common-english-words.txt'):\n",
      "    stop_words_list.extend(line.strip().split(','))\n",
      "\n",
      "stop_word_set = set(stop_words_list)\n",
      "\n",
      "def normalize_dict_values(d):\n",
      "    total_value = np.sum(d.values())\n",
      "    return dict([(k,  float(v) / total_value) for k, v in d.iteritems()])\n",
      "\n",
      "\n",
      "train_data['summary_words'] = train_data['summary_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "train_data['summary_words'] = train_data['summary_words'].apply(lambda x: normalize_dict_values(x))\n",
      "\n",
      "\n",
      "train_data['description_words'] = train_data['description_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "train_data['description_words'] = train_data['description_words'].apply(lambda x: normalize_dict_values(x))\n",
      "\n",
      "\n",
      "\n",
      "test_data['summary_words'] = test_data['summary_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "test_data['summary_words'] = test_data['summary_words'].apply(lambda x: normalize_dict_values(x))\n",
      "\n",
      "\n",
      "test_data['description_words'] = test_data['description_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "test_data['description_words'] = test_data['description_words'].apply(lambda x: normalize_dict_values(x))\n",
      "\n",
      "train_data.head(1)\n",
      "test_data.head(1)\n",
      "\n",
      "keylist = ['latitude', 'longitude']\n",
      "\n",
      "lat_log_info = train_data.select_columns(keylist)\n",
      "lat_log_info = lat_log_info.append(test_data.select_columns(keylist))\n",
      "\n",
      "out = gl.kmeans.create(lat_log_info, num_clusters=4, max_iter=30)        \n",
      "label = out.get('clusterid')\n",
      "geo_label_4_train = SArray(data = label['clusterid'][:train_data.num_rows()], dtype=str)\n",
      "geo_label_4_test = SArray(data = label['clusterid'][train_data.num_rows():], dtype=str)\n",
      "\n",
      "out = gl.kmeans.create(lat_log_info, num_clusters=40, max_iter=30)        \n",
      "label = out.get('clusterid')\n",
      "geo_label_40_train = SArray(data = label['clusterid'][:train_data.num_rows()], dtype=int)\n",
      "geo_label_40_test = SArray(data = label['clusterid'][train_data.num_rows():], dtype=int)\n",
      "\n",
      "train_data['geo_label_4'] = geo_label_4_train\n",
      "test_data['geo_label_4'] = geo_label_4_test\n",
      "\n",
      "train_data['geo_label_40'] = geo_label_40_train\n",
      "test_data['geo_label_40'] = geo_label_40_test\n",
      "\n",
      "train_data['geo_label_4'] = train_data['geo_label_4'].apply(lambda x: str(x))\n",
      "test_data['geo_label_4'] = test_data['geo_label_4'].apply(lambda x: str(x))\n",
      "train_data['geo_label_40'] = train_data['geo_label_40'].apply(lambda x: str(x))\n",
      "test_data['geo_label_40'] = test_data['geo_label_40'].apply(lambda x: str(x))\n",
      "\n",
      "train_data.head(1)\n",
      "test_data.head(1)\n",
      "\n",
      "\n",
      "train_data['log_num_votes'] = train_data['num_votes'].apply(lambda x: np.log(1. + x))\n",
      "train_data['log_num_views'] = train_data['num_views'].apply(lambda x: np.log(1. + x))\n",
      "train_data['log_num_comments'] = train_data['num_comments'].apply(lambda x: np.log(1. + x))\n",
      "\n",
      "train_data['summary_length'] = train_data['summary_length'].apply(lambda x: str(x) if x <=5 else '6')\n",
      "test_data['summary_length'] = test_data['summary_length'].apply(lambda x: str(x) if x <=5 else '6')\n",
      "\n",
      "train_data.head(1)\n",
      "test_data.head(1)\n",
      "#     train_data.save('train_data')\n",
      "#     test_data.save('test_data')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] Using MetricMock instead of real metrics, mode is: UNIT\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "A newer version of GraphLab Create (v0.3) is available! Your current version is v{{VERSION_STRING}}.\n",
        "You can use pip to upgrade the graphlab-create package. For more information see http://graphlab.com/products/create/upgrade.[INFO] Start server at: ipc:///tmp/graphlab_server-698 - Server binary: /Users/yaowu/work/graphlab-dev/debug/src/unity/server/unity_server - Server log: /tmp/graphlab_server_1402548559.log\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[INFO] GraphLab Server Version: 0.1.internal\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[ERROR] Toolkit error: WARNING: Clustering has not converged within max iterations\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>summary</th>\n",
        "      <th>description</th>\n",
        "      <th>source</th>\n",
        "      <th>created_time</th>\n",
        "      <th>tag_type</th>\n",
        "      <th>summary_length</th>\n",
        "      <th>description_words</th>\n",
        "      <th>summary_words</th>\n",
        "      <th>geo_label_4</th>\n",
        "      <th>geo_label_40</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 21523</td>\n",
        "      <td> 41.913652</td>\n",
        "      <td>-87.70605</td>\n",
        "      <td> Graffiti Removal</td>\n",
        "      <td> </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:13:47</td>\n",
        "      <td> NA</td>\n",
        "      <td> 2</td>\n",
        "      <td> {}</td>\n",
        "      <td> {u'graffiti': 0.5, u'removal': 0.5}</td>\n",
        "      <td> 1</td>\n",
        "      <td> 21</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1 rows \u00d7 13 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "      id   latitude  longitude           summary description  \\\n",
        "0  21523  41.913652  -87.70605  Graffiti Removal               \n",
        "\n",
        "               source         created_time tag_type summary_length  \\\n",
        "0  remote_api_created  2013-05-01 00:13:47       NA              2   \n",
        "\n",
        "  description_words                        summary_words geo_label_4  \\\n",
        "0                {}  {u'graffiti': 0.5, u'removal': 0.5}           1   \n",
        "\n",
        "  geo_label_40  \n",
        "0           21  \n",
        "\n",
        "[1 rows x 13 columns]"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from graphlab import *\n",
      "import numpy as np\n",
      "\n",
      "import graphlab as gl\n",
      "\n",
      "train_data = gl.SFrame.read_csv('./train.csv', error_bad_lines=False, column_type_hints = {'id': int, 'latitude': float, \n",
      "                            'longitude': float,\n",
      "                            'num_votes': int,\n",
      "                            'num_comments': int,\n",
      "                            'num_views': int})\n",
      "\n",
      "test_data = gl.SFrame.read_csv('./test.csv', error_bad_lines=False, column_type_hints = {'id': int, 'latitude': float, \n",
      "                            'longitude': float,\n",
      "                            'num_votes': int,\n",
      "                            'num_comments': int,\n",
      "                            'num_views': int})\n",
      "\n",
      "train_data['summary_length'] = train_data['summary'].apply(lambda x: len(x.strip().split()))\n",
      "test_data['summary_length'] = test_data['summary'].apply(lambda x: len(x.strip().split()))\n",
      "\n",
      "train_data['description_words'] = train_data['description'].count_words()\n",
      "test_data['description_words'] = test_data['description'].count_words()\n",
      "\n",
      "train_data['summary_words'] = train_data['summary'].count_words()\n",
      "test_data['summary_words'] = test_data['summary'].count_words()\n",
      "\n",
      "train_data.head(1)\n",
      "test_data.head(1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>summary</th>\n",
        "      <th>description</th>\n",
        "      <th>source</th>\n",
        "      <th>created_time</th>\n",
        "      <th>tag_type</th>\n",
        "      <th>summary_length</th>\n",
        "      <th>description_words</th>\n",
        "      <th>summary_words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 21523</td>\n",
        "      <td> 41.913652</td>\n",
        "      <td>-87.70605</td>\n",
        "      <td> Graffiti Removal</td>\n",
        "      <td> </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:13:47</td>\n",
        "      <td> NA</td>\n",
        "      <td> 2</td>\n",
        "      <td> {}</td>\n",
        "      <td> {u'graffiti': 1, u'removal': 1}</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>1 rows \u00d7 11 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "      id   latitude  longitude           summary description  \\\n",
        "0  21523  41.913652  -87.70605  Graffiti Removal               \n",
        "\n",
        "               source         created_time tag_type  summary_length  \\\n",
        "0  remote_api_created  2013-05-01 00:13:47       NA               2   \n",
        "\n",
        "  description_words                    summary_words  \n",
        "0                {}  {u'graffiti': 1, u'removal': 1}  \n",
        "\n",
        "[1 rows x 11 columns]"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from collections import defaultdict\n",
      "word_dict = defaultdict(int)\n",
      "for row in train_data['summary_words']:\n",
      "    for w, c in row.iteritems():\n",
      "        word_dict[w] += c\n",
      "\n",
      "stop_words = 'common-english-words.txt'\n",
      "stop_words_list = []\n",
      "\n",
      "for line in file('common-english-words.txt'):\n",
      "    stop_words_list.extend(line.strip().split(','))\n",
      "\n",
      "stop_word_set = set(stop_words_list)\n",
      "\n",
      "def normalize_dict_values(d):\n",
      "    total_value = np.sum(d.values())\n",
      "    return dict([(k, float(v) / total_value) for k, v in d.iteritems()])\n",
      "\n",
      "\n",
      "train_data['summary_words'] = train_data['summary_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "train_data['summary_words'] = train_data['summary_words'].apply(normalize_dict_values)\n",
      "\n",
      "\n",
      "train_data['description_words'] = train_data['description_words'].apply(lambda x: dict([(k,v) for k,v in x.iteritems() \n",
      "                                                                                    if k not in stop_word_set])) \n",
      "train_data['description_words'] = train_data['description_words'].apply(lambda x: normalize_dict_values(x))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_data['summary_words'].head()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[{'alleyway': 0.3333333333333333,\n",
        "  'light': 0.3333333333333333,\n",
        "  'out': 0.3333333333333333},\n",
        " {'brick': 0.2, 'hole': 0.2, 'side': 0.2, 'sink': 0.2, 'walk': 0.2},\n",
        " {'graffiti': 1.0},\n",
        " {'functioning': 0.25, 'lights': 0.25, 'non': 0.25, 'traffic': 0.25},\n",
        " {'crosswalk': 0.5, 'pothole': 0.5},\n",
        " {'bus': 0.16666666666666666,\n",
        "  'light': 0.16666666666666666,\n",
        "  'near': 0.16666666666666666,\n",
        "  'out': 0.16666666666666666,\n",
        "  'stop': 0.16666666666666666,\n",
        "  'street': 0.16666666666666666},\n",
        " {'pothole': 1.0},\n",
        " {'pothole': 1.0},\n",
        " {'potholes': 1.0},\n",
        " {'dumped': 0.16666666666666666,\n",
        "  'front': 0.16666666666666666,\n",
        "  'house': 0.16666666666666666,\n",
        "  'someone': 0.16666666666666666,\n",
        "  'tire': 0.16666666666666666,\n",
        "  'tv': 0.16666666666666666}]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "      <th>latitude</th>\n",
        "      <th>longitude</th>\n",
        "      <th>summary</th>\n",
        "      <th>description</th>\n",
        "      <th>source</th>\n",
        "      <th>created_time</th>\n",
        "      <th>tag_type</th>\n",
        "      <th>summary_length</th>\n",
        "      <th>description_words</th>\n",
        "      <th>summary_words</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  21523</td>\n",
        "      <td> 41.913652</td>\n",
        "      <td>-87.706050</td>\n",
        "      <td>     Graffiti Removal</td>\n",
        "      <td>                                                  </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:13:47</td>\n",
        "      <td>      NA</td>\n",
        "      <td> 2</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td>                 {u'graffiti': 1, u'removal': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  87152</td>\n",
        "      <td> 41.913646</td>\n",
        "      <td>-87.706479</td>\n",
        "      <td>     Graffiti Removal</td>\n",
        "      <td>                                                  </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:14:57</td>\n",
        "      <td>      NA</td>\n",
        "      <td> 2</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td>                 {u'graffiti': 1, u'removal': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 182789</td>\n",
        "      <td> 41.992691</td>\n",
        "      <td>-87.663184</td>\n",
        "      <td>     Graffiti Removal</td>\n",
        "      <td>                                                  </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:18:49</td>\n",
        "      <td>      NA</td>\n",
        "      <td> 2</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td>                 {u'graffiti': 1, u'removal': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 312571</td>\n",
        "      <td> 41.702686</td>\n",
        "      <td>-87.525743</td>\n",
        "      <td>   Traffic Signal Out</td>\n",
        "      <td>              Assigned to Traffic Signal Repairman</td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:18:49</td>\n",
        "      <td>      NA</td>\n",
        "      <td> 3</td>\n",
        "      <td> {u'assigned': 1, u'to': 1, u'signal': 1, u'rep...</td>\n",
        "      <td>        {u'signal': 1, u'traffic': 1, u'out': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 246776</td>\n",
        "      <td> 41.724424</td>\n",
        "      <td>-87.643293</td>\n",
        "      <td> Street Light 1 / Out</td>\n",
        "      <td>                                                  </td>\n",
        "      <td> remote_api_created</td>\n",
        "      <td> 2013-05-01 00:25:40</td>\n",
        "      <td>      NA</td>\n",
        "      <td> 5</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td> {u'1': 1, u'light': 1, u'street': 1, u'out': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>  86278</td>\n",
        "      <td> 37.590796</td>\n",
        "      <td>-77.454462</td>\n",
        "      <td>  Re-occuring pothole</td>\n",
        "      <td> The repatched patch at this pothole needs to b...</td>\n",
        "      <td>                web</td>\n",
        "      <td> 2013-05-01 00:28:14</td>\n",
        "      <td> pothole</td>\n",
        "      <td> 2</td>\n",
        "      <td> {u'and': 1, u'again': 1, u'needs': 1, u'good':...</td>\n",
        "      <td>       {u'occuring': 1, u'pothole': 1, u're': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 408061</td>\n",
        "      <td> 41.957306</td>\n",
        "      <td>-87.726425</td>\n",
        "      <td>    Pothole in Street</td>\n",
        "      <td>                                                  </td>\n",
        "      <td>             iphone</td>\n",
        "      <td> 2013-05-01 00:28:57</td>\n",
        "      <td> pothole</td>\n",
        "      <td> 3</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td>         {u'pothole': 1, u'street': 1, u'in': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 119989</td>\n",
        "      <td> 41.957291</td>\n",
        "      <td>-87.726646</td>\n",
        "      <td>    Pothole in Street</td>\n",
        "      <td>                                                  </td>\n",
        "      <td>             iphone</td>\n",
        "      <td> 2013-05-01 00:28:57</td>\n",
        "      <td> pothole</td>\n",
        "      <td> 3</td>\n",
        "      <td>                                                {}</td>\n",
        "      <td>         {u'pothole': 1, u'street': 1, u'in': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 247786</td>\n",
        "      <td> 37.590551</td>\n",
        "      <td>-77.463420</td>\n",
        "      <td>   Reoccuring Pothole</td>\n",
        "      <td> The repatched patch at this pothole needs to b...</td>\n",
        "      <td>                web</td>\n",
        "      <td> 2013-05-01 00:29:46</td>\n",
        "      <td> pothole</td>\n",
        "      <td> 2</td>\n",
        "      <td> {u'and': 1, u'again': 1, u'needs': 1, u'good':...</td>\n",
        "      <td>               {u'pothole': 1, u'reoccuring': 1}</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>  33437</td>\n",
        "      <td> 41.955814</td>\n",
        "      <td>-87.723679</td>\n",
        "      <td>             Potholes</td>\n",
        "      <td>                                          Potholes</td>\n",
        "      <td>             iphone</td>\n",
        "      <td> 2013-05-01 00:31:23</td>\n",
        "      <td> pothole</td>\n",
        "      <td> 1</td>\n",
        "      <td>                                  {u'potholes': 1}</td>\n",
        "      <td>                                {u'potholes': 1}</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 11 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "       id   latitude  longitude               summary  \\\n",
        "0   21523  41.913652 -87.706050      Graffiti Removal   \n",
        "1   87152  41.913646 -87.706479      Graffiti Removal   \n",
        "2  182789  41.992691 -87.663184      Graffiti Removal   \n",
        "3  312571  41.702686 -87.525743    Traffic Signal Out   \n",
        "4  246776  41.724424 -87.643293  Street Light 1 / Out   \n",
        "5   86278  37.590796 -77.454462   Re-occuring pothole   \n",
        "6  408061  41.957306 -87.726425     Pothole in Street   \n",
        "7  119989  41.957291 -87.726646     Pothole in Street   \n",
        "8  247786  37.590551 -77.463420    Reoccuring Pothole   \n",
        "9   33437  41.955814 -87.723679              Potholes   \n",
        "\n",
        "                                         description              source  \\\n",
        "0                                                     remote_api_created   \n",
        "1                                                     remote_api_created   \n",
        "2                                                     remote_api_created   \n",
        "3               Assigned to Traffic Signal Repairman  remote_api_created   \n",
        "4                                                     remote_api_created   \n",
        "5  The repatched patch at this pothole needs to b...                 web   \n",
        "6                                                                 iphone   \n",
        "7                                                                 iphone   \n",
        "8  The repatched patch at this pothole needs to b...                 web   \n",
        "9                                           Potholes              iphone   \n",
        "\n",
        "          created_time tag_type  summary_length  \\\n",
        "0  2013-05-01 00:13:47       NA               2   \n",
        "1  2013-05-01 00:14:57       NA               2   \n",
        "2  2013-05-01 00:18:49       NA               2   \n",
        "3  2013-05-01 00:18:49       NA               3   \n",
        "4  2013-05-01 00:25:40       NA               5   \n",
        "5  2013-05-01 00:28:14  pothole               2   \n",
        "6  2013-05-01 00:28:57  pothole               3   \n",
        "7  2013-05-01 00:28:57  pothole               3   \n",
        "8  2013-05-01 00:29:46  pothole               2   \n",
        "9  2013-05-01 00:31:23  pothole               1   \n",
        "\n",
        "                                   description_words  \\\n",
        "0                                                 {}   \n",
        "1                                                 {}   \n",
        "2                                                 {}   \n",
        "3  {u'assigned': 1, u'to': 1, u'signal': 1, u'rep...   \n",
        "4                                                 {}   \n",
        "5  {u'and': 1, u'again': 1, u'needs': 1, u'good':...   \n",
        "6                                                 {}   \n",
        "7                                                 {}   \n",
        "8  {u'and': 1, u'again': 1, u'needs': 1, u'good':...   \n",
        "9                                   {u'potholes': 1}   \n",
        "\n",
        "                                     summary_words  \n",
        "0                  {u'graffiti': 1, u'removal': 1}  \n",
        "1                  {u'graffiti': 1, u'removal': 1}  \n",
        "2                  {u'graffiti': 1, u'removal': 1}  \n",
        "3         {u'signal': 1, u'traffic': 1, u'out': 1}  \n",
        "4  {u'1': 1, u'light': 1, u'street': 1, u'out': 1}  \n",
        "5        {u'occuring': 1, u'pothole': 1, u're': 1}  \n",
        "6          {u'pothole': 1, u'street': 1, u'in': 1}  \n",
        "7          {u'pothole': 1, u'street': 1, u'in': 1}  \n",
        "8                {u'pothole': 1, u'reoccuring': 1}  \n",
        "9                                 {u'potholes': 1}  \n",
        "\n",
        "[10 rows x 11 columns]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "m1 = linear_regression.create(train_data, 'log_num_votes', features = ['source', 'tag_type','geo_label_4','geo_label_40', \n",
      "                                                                       'description_words','summary_length','summary_words'],\n",
      "                                          L2_penalty=1, solver_options = {'max_iterations' : 50})\n",
      "\n",
      "predictions1 = m1.predict(test_data) \n",
      "\n",
      "m2 = linear_regression.create(train_data, 'log_num_views', features = ['source', 'tag_type','geo_label_4','geo_label_40', \n",
      "                                                                       'description_words','summary_length','summary_words'],\n",
      "                                          L2_penalty=1, solver_options = {'max_iterations' : 50})\n",
      "\n",
      "predictions2 = m2.predict(test_data) \n",
      "\n",
      "m3 = linear_regression.create(train_data, 'log_num_comments', features = ['source', 'tag_type','geo_label_4','geo_label_40', \n",
      "                                                                       'description_words','summary_length','summary_words'],\n",
      "                                          L2_penalty=1, solver_options = {'max_iterations' : 50})\n",
      "\n",
      "predictions3 = m3.predict(test_data) \n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Starting pre-training...\n",
        "Starting training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                    Model summary                       \n",
        "--------------------------------------------------------\n",
        "Class                   : LinearRegressionModel\n",
        "L1 penalty              : 0.0\n",
        "L2 penalty              : 1\n",
        "Examples                : 223128\n",
        "Features                : 7\n",
        "Coefficients            : 32557\n",
        "\n",
        "Solver                  : auto\n",
        "Solver iterations       : 50\n",
        "Solver status           : TERMINATED: Iteration limit reached.\n",
        "Training time (sec)     : 417.2427\n",
        "\n",
        "Residual sum of squares : 5882.9267\n",
        "Training RMSE           : 0.1624\n",
        "\n",
        "             Strongest positive coefficients            \n",
        "--------------------------------------------------------\n",
        "                  Feature  Coefficient\n",
        "0             (intercept)     1.167859\n",
        "1          geo_label_4[3]     0.172386\n",
        "2  tag_type[bike_concern]     0.169025\n",
        "3         geo_label_40[3]     0.161632\n",
        "4             source[web]     0.139598\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             Strongest negative coefficients            \n",
        "--------------------------------------------------------\n",
        "                      Feature  Coefficient\n",
        "0           tag_type[hydrant]    -0.477790\n",
        "1     summary_words[trimming]    -0.350821\n",
        "2  source[remote_api_created]    -0.300543\n",
        "3     description_words[tree]    -0.184551\n",
        "4         summary_words[tree]    -0.174053\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting pre-training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                    Model summary                       \n",
        "--------------------------------------------------------\n",
        "Class                   : LinearRegressionModel\n",
        "L1 penalty              : 0.0\n",
        "L2 penalty              : 1\n",
        "Examples                : 223128\n",
        "Features                : 7\n",
        "Coefficients            : 32557\n",
        "\n",
        "Solver                  : auto\n",
        "Solver iterations       : 50\n",
        "Solver status           : TERMINATED: Iteration limit reached.\n",
        "Training time (sec)     : 431.9862\n",
        "\n",
        "Residual sum of squares : 121756.5544\n",
        "Training RMSE           : 0.7387\n",
        "\n",
        "             Strongest positive coefficients            \n",
        "--------------------------------------------------------\n",
        "                   Feature  Coefficient\n",
        "0              (intercept)     2.644557\n",
        "1           geo_label_4[3]     0.800713\n",
        "2    summary_words[debris]     0.668451\n",
        "3  tag_type[drain_problem]     0.466926\n",
        "4         geo_label_40[36]     0.465619\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             Strongest negative coefficients            \n",
        "--------------------------------------------------------\n",
        "                      Feature  Coefficient\n",
        "0  source[remote_api_created]    -1.890732\n",
        "1           tag_type[hydrant]    -1.860877\n",
        "2     summary_words[trimming]    -1.591101\n",
        "3     description_words[tree]    -1.084038\n",
        "4         summary_words[tree]    -0.971523\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting pre-training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Starting training..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "                    Model summary                       \n",
        "--------------------------------------------------------\n",
        "Class                   : LinearRegressionModel\n",
        "L1 penalty              : 0.0\n",
        "L2 penalty              : 1\n",
        "Examples                : 223128\n",
        "Features                : 7\n",
        "Coefficients            : 32557\n",
        "\n",
        "Solver                  : auto\n",
        "Solver iterations       : 50\n",
        "Solver status           : TERMINATED: Iteration limit reached.\n",
        "Training time (sec)     : 431.9475\n",
        "\n",
        "Residual sum of squares : 8762.6332\n",
        "Training RMSE           : 0.1982\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             Strongest positive coefficients            \n",
        "--------------------------------------------------------\n",
        "                  Feature  Coefficient\n",
        "0          geo_label_4[3]     0.355223\n",
        "1  tag_type[bike_concern]     0.245320\n",
        "2        geo_label_40[36]     0.177156\n",
        "3   tag_type[road_safety]     0.158308\n",
        "4          geo_label_4[1]     0.143158\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "             Strongest negative coefficients            \n",
        "--------------------------------------------------------\n",
        "                      Feature  Coefficient\n",
        "0     summary_words[trimming]    -0.516828\n",
        "1           tag_type[hydrant]    -0.492084\n",
        "2  source[remote_api_created]    -0.174878\n",
        "3     description_words[tree]    -0.170651\n",
        "4        summary_words[stump]    -0.168507\n",
        "\n",
        "[5 rows x 2 columns]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "TypeError",
       "evalue": "Unexpected data source. Possible data source types are: list, numpy.ndarray, pandas.Series, and string(url)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-a75f6bb3a37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpredictions3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'num_views'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_views'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_views'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yaowu/work/graphlab-dev/debug/src/unity/python/graphlab/data_structures/sframe.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, format, _proxy)\u001b[0m\n\u001b[1;32m    425\u001b[0m                             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot create SFrame from mix of regular values and SArrays\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__proxy__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/yaowu/work/graphlab-dev/debug/src/unity/python/graphlab/data_structures/sarray.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dtype, ignore_cast_failure, _proxy)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m                 raise TypeError(\"Unexpected data source. \" \\\n\u001b[0m\u001b[1;32m    318\u001b[0m                                 \u001b[0;34m\"Possible data source types are: list, \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                                 \"numpy.ndarray, pandas.Series, and string(url)\")\n",
        "\u001b[0;31mTypeError\u001b[0m: Unexpected data source. Possible data source types are: list, numpy.ndarray, pandas.Series, and string(url)"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf = SFrame({'id' : test_data['id'], 'num_views': predictions2, 'num_votes': predictions1, 'num_comments': predictions3})\n",
      "sf['num_views'] = sf['num_views'].apply(lambda x: np.exp(x) - 1. if x > 0. else 0.)\n",
      "sf['num_votes'] = sf['num_votes'].apply(lambda x: np.exp(x) - 1. if x > 0. else 0.)\n",
      "sf['num_comments'] = sf['num_comments'].apply(lambda x: np.exp(x) - 1. if x > 0. else 0.)\n",
      "\n",
      "sf.save('upload', format='csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>id</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>  21523</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>  87152</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 182789</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 312571</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 246776</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>  86278</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td> 408061</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td> 119989</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 247786</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>  33437</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>10 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "       id\n",
        "0   21523\n",
        "1   87152\n",
        "2  182789\n",
        "3  312571\n",
        "4  246776\n",
        "5   86278\n",
        "6  408061\n",
        "7  119989\n",
        "8  247786\n",
        "9   33437\n",
        "\n",
        "[10 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}